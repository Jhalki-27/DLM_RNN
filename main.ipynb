{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment Analysis with RNN - Full Pipeline using IMDB Dataset\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import pickle\n",
    "\n",
    "from tensorflow.keras.models import Sequential  # type: ignore\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional  # type: ignore\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences  # type: ignore\n",
    "from tensorflow.keras.datasets import imdb  # type: ignore\n",
    "from tensorflow.keras.models import load_model  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_5\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_5 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 90ms/step - accuracy: 0.7216 - loss: 0.5123 - val_accuracy: 0.8483 - val_loss: 0.3554\n",
      "Epoch 2/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 107ms/step - accuracy: 0.9111 - loss: 0.2350 - val_accuracy: 0.8688 - val_loss: 0.3189\n",
      "Epoch 3/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 98ms/step - accuracy: 0.9349 - loss: 0.1734 - val_accuracy: 0.8677 - val_loss: 0.3189\n",
      "Epoch 4/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 117ms/step - accuracy: 0.9533 - loss: 0.1325 - val_accuracy: 0.8542 - val_loss: 0.4351\n",
      "Epoch 5/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 104ms/step - accuracy: 0.9638 - loss: 0.1036 - val_accuracy: 0.8636 - val_loss: 0.4224\n",
      "Epoch 6/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 103ms/step - accuracy: 0.9750 - loss: 0.0754 - val_accuracy: 0.8534 - val_loss: 0.5416\n",
      "Epoch 7/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 102ms/step - accuracy: 0.9794 - loss: 0.0605 - val_accuracy: 0.8538 - val_loss: 0.4902\n",
      "Epoch 8/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 153ms/step - accuracy: 0.9846 - loss: 0.0492 - val_accuracy: 0.8576 - val_loss: 0.6057\n",
      "Epoch 9/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 159ms/step - accuracy: 0.9889 - loss: 0.0350 - val_accuracy: 0.8564 - val_loss: 0.6218\n",
      "Epoch 10/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 160ms/step - accuracy: 0.9908 - loss: 0.0311 - val_accuracy: 0.8468 - val_loss: 0.6028\n"
     ]
    }
   ],
   "source": [
    "# Load IMDB dataset\n",
    "vocab_size = 10000\n",
    "maxlen = 200\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=vocab_size)\n",
    "\n",
    "# Get word index and reverse it for decoding\n",
    "word_index = imdb.get_word_index()\n",
    "reverse_word_index = {value: key for key, value in word_index.items()}\n",
    "\n",
    "# Decode integer to text (for preprocessing reviews)\n",
    "def decode_review(encoded):\n",
    "    return ' '.join([reverse_word_index.get(i - 3, '?') for i in encoded if i >= 3])\n",
    "\n",
    "# Preprocess: pad sequences\n",
    "X_train = pad_sequences(X_train, maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, maxlen=maxlen)\n",
    "\n",
    "# Save word index\n",
    "with open(\"word_index.pkl\", \"wb\") as f:\n",
    "    pickle.dump(word_index, f)\n",
    "\n",
    "# Model definition with Bidirectional LSTM for improved context understanding\n",
    "model = Sequential([\n",
    "    Embedding(vocab_size, 64),\n",
    "    Bidirectional(LSTM(64)),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# Train model with increased epochs and silent output\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=1,\n",
    "    batch_size=16384,\n",
    "    validation_data=(X_test, y_test),\n",
    "    verbose=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S.No</th>\n",
       "      <th>Review</th>\n",
       "      <th>Sentiment Score</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>The movie was barely satisfactory</td>\n",
       "      <td>3.36%</td>\n",
       "      <td>Negative 😞</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>I loved it just a little bit.</td>\n",
       "      <td>51.06%</td>\n",
       "      <td>Neutral 😐</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Amazing movie! Definitely worth watching.</td>\n",
       "      <td>99.51%</td>\n",
       "      <td>Positive 😄</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>It was fine, but nothing special or thrilling.</td>\n",
       "      <td>0.77%</td>\n",
       "      <td>Negative 😞</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>I didn’t like it at all and wouldn’t tell others to watch it.</td>\n",
       "      <td>1.30%</td>\n",
       "      <td>Negative 😞</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>I hated it only a little.</td>\n",
       "      <td>57.96%</td>\n",
       "      <td>Neutral 😐</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>The movie had amazing characters</td>\n",
       "      <td>97.80%</td>\n",
       "      <td>Positive 😄</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   S.No                                                         Review  \\\n",
       "0     1                              The movie was barely satisfactory   \n",
       "1     2                                  I loved it just a little bit.   \n",
       "2     3                      Amazing movie! Definitely worth watching.   \n",
       "3     4                 It was fine, but nothing special or thrilling.   \n",
       "4     5  I didn’t like it at all and wouldn’t tell others to watch it.   \n",
       "5     6                                      I hated it only a little.   \n",
       "6     7                               The movie had amazing characters   \n",
       "\n",
       "  Sentiment Score   Sentiment  \n",
       "0           3.36%  Negative 😞  \n",
       "1          51.06%   Neutral 😐  \n",
       "2          99.51%  Positive 😄  \n",
       "3           0.77%  Negative 😞  \n",
       "4           1.30%  Negative 😞  \n",
       "5          57.96%   Neutral 😐  \n",
       "6          97.80%  Positive 😄  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load word index for inference\n",
    "def load_word_index():\n",
    "    with open(\"word_index.pkl\", \"rb\") as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "# Encode custom review using IMDB word index\n",
    "def encode_review_custom(text, word_index, maxlen=200, vocab_limit=10000):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
    "    tokens = text.split()\n",
    "    encoded = [word_index.get(word, 2) for word in tokens]  # 2 = OOV token\n",
    "\n",
    "    # Limit to vocab range (as per embedding input_dim)\n",
    "    encoded = [i if i < vocab_limit else 2 for i in encoded]\n",
    "    return pad_sequences([encoded], maxlen=maxlen)\n",
    "\n",
    "# Predict on new reviews\n",
    "custom_reviews = [\n",
    "    \"The movie was barely satisfactory\",\n",
    "    \"I loved it just a little bit.\",\n",
    "    \"Amazing movie! Definitely worth watching.\",\n",
    "    \"It was fine, but nothing special or thrilling.\",\n",
    "    \"I didn’t like it at all and wouldn’t tell others to watch it.\",\n",
    "    \"I hated it only a little.\",\n",
    "    \"The movie had amazing characters\"\n",
    "]\n",
    "\n",
    "word_index = load_word_index()\n",
    "knowledge_graphs = load_model(\"sentiment_rnn_model_imdb.keras\")\n",
    "results = []\n",
    "\n",
    "for idx, review in enumerate(custom_reviews, start=1):\n",
    "    encoded = encode_review_custom(review, word_index)\n",
    "    prediction = knowledge_graphs.predict(encoded, verbose=0)\n",
    "    score = float(prediction[0][0])\n",
    "    if score > 0.65:\n",
    "        sentiment = \"Positive 😄\"\n",
    "    elif score < 0.35:\n",
    "        sentiment = \"Negative 😞\"\n",
    "    else:\n",
    "        sentiment = \"Neutral 😐\"\n",
    "    results.append({\n",
    "        \"S.No\": idx,\n",
    "        \"Review\": review,\n",
    "        \"Sentiment Score\": f\"{score:.2%}\",\n",
    "        \"Sentiment\": sentiment\n",
    "    })\n",
    "\n",
    "result_df = pd.DataFrame(results)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "display(result_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
